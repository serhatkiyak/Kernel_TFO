#! /usr/bin/env python

import os
import sys
import logging
import argparse
import pickle
from collections import defaultdict

sys.path.append(os.path.join(os.path.dirname(__file__), 'web-profiler'))
from webloader.tcp_loader import TCPLoader
from webloader.loader import LoadResult, PageResult


def print_tfo_stats(loader):
    '''Print TFO stats for manual inspection'''
    print 'TFO Statuses:'
    for url, page_result in loader.page_results.iteritems():
        print '{:<30}{:<20}{:<}'.format(url, 
            page_result.tcp_fast_open_support_statuses, page_result.server)

def print_errors(loader):
    '''Print success/error statuses for manual inspection'''
    print 'Errors:'
    for url, page_result in loader.page_results.iteritems():
        if page_result.status != PageResult.SUCCESS:
            print '{:<30}{:<}'.format(url,\
                [result.status for result in loader.load_results[url]])

def print_summary_stats(loader):
    success_count = 0  # number of pages successfully loaded
    success_with_tfo_count = 0  # page successfully loaded AND supported TFO
    urls_with_tfo = []
    server_to_tfo_count = defaultdict(int)
    server_to_total_count = defaultdict(int)

    for url, page_result in loader.page_results.iteritems():
        if page_result.status == PageResult.SUCCESS:
            success_count += 1
            server_to_total_count[page_result.server] += 1
            if True in page_result.tcp_fast_open_support_statuses:
                success_with_tfo_count += 1
                urls_with_tfo.append(url)
                server_to_tfo_count[page_result.server] += 1

    print 'TFO support:\t%d/%d  (%.02f %%)\n' % \
        (success_with_tfo_count, success_count,\
         float(success_with_tfo_count)/success_count*100.0)

    print 'Server support: (# domains with support / # domains)'
    for server in server_to_tfo_count:
        print '{:<20}{:<}'.format(server, '%d / %d' % \
            (server_to_tfo_count[server], server_to_total_count[server]))
    print ''

    print 'URLs with TFO support:'
    for url in urls_with_tfo:
        print url
    print ''


def main():
    logging.info('Loading pickled loader: %s' % args.loader)

    with open(args.loader, 'r') as f:
        loader = pickle.load(f)

    print_summary_stats(loader)

    if args.verbose:
        print_errors(loader)
        print '\n\n'
        print_tfo_stats(loader)



if __name__ == "__main__":
    # set up command line args
    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter,\
                                     description='Web page profiler.')
    parser.add_argument('loader', help='Pickled loader file generated by crawler')
    parser.add_argument('-o', '--outdir', default='.', help='Destination directory for pickled results.')
    parser.add_argument('-q', '--quiet', action='store_true', default=False, help='only print errors')
    parser.add_argument('-v', '--verbose', action='store_true', default=False, help='print debug info. --quiet wins if both are present')
    args = parser.parse_args()

    if not os.path.isdir(args.outdir):
        try:
            os.makedirs(args.outdir)
        except Exception as e:
            logging.getLogger(__name__).error('Error making output directory: %s' % args.outdir)
            sys.exit(-1)
    
    # set up logging
    if args.quiet:
        level = logging.WARNING
    elif args.verbose:
        level = logging.DEBUG
    else:
        level = logging.INFO
    logfmt = "%(levelname) -10s %(asctime)s %(module)s:%(lineno) -7s %(message)s"
    config = {
        'format' : logfmt,
        'level' : level
    }
    logging.basicConfig(**config)

    main()
